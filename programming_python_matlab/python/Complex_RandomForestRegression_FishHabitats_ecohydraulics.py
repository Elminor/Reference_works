# -*- coding: utf-8 -*-
"""RandomForest_Regression_Halak.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Lhw7KrHa8tqCPYEO6t1rDNeztO7HRAse
"""

# xlrd is needed to load excel files
!pip install xlrd
!pip install psycopg2

import pandas as pd
import numpy  as np
import matplotlib.pyplot as plt
import psycopg2 as ps
import folium
from google.colab import files

from sklearn.ensemble import RandomForestRegressor
# Install TensorFlow Dececision Forests.
!pip install tensorflow_decision_forests

# Use wurlitzer to show the training logs.
!pip install wurlitzer
import tensorflow_decision_forests as tfdf

import os
import tensorflow as tf
import matplotlib.pyplot as plt
import math
import collections
import time

#file feltöltése, categória elkülönítése
data = pd.read_excel( 'adatok-fv.xlsx')
print(data)

x = data.iloc[:,3:12]
print(x)
mederanyag = x['homok_kavics_ko_(1_2_3)']
print(mederanyag)

Y = data.iloc[:,12:]
print(Y)

"""# **8. neomel:**



"""

y_neomel = Y.iloc[:,8]
print(y_neomel)

fig, ax = plt.subplots()
y_neomel.hist(bins=100, ax=ax)
ax.annotate('kiugró',
            xy=(y_neomel.max()-4, 20),
            xytext=(y_neomel.max()-4, 140),
            arrowprops=dict(color='red',width=1),
            horizontalalignment='center',
            size=14)
plt.show()

def label_outliers_iqr(df, column_to_filter, k=1.5, outlier_col='outlier', verbose=False):
  df = df.copy()
  quartiles = df[column_to_filter].quantile([.25, .75])
  iqr = np.abs(quartiles.iloc[1] - quartiles.iloc[0])
  tolerable_range = pd.Series([quartiles.iloc[0] - k*iqr - 0.01, quartiles.iloc[1] + k*iqr + 0.01 ])
  df[outlier_col] = (df[column_to_filter].isna() | df[column_to_filter].clip(*tolerable_range).isin(tolerable_range)) # clip sets values outside the range equal to the boundaries

  if(verbose):
    num_nullvalues = df[column_to_filter].isna().sum()
    num_outliers = df[outlier_col].sum() - num_nullvalues
    print("Found {0} null values and {1} outliers.".format(num_nullvalues, num_outliers))
  return(df)

column2plot_neomel = 'neomel'
outlier_tolerance_k = 14 # larger means you tolerate more extreme values. For gaussian data, standard is 1.5.

data_labeled_neomel = label_outliers_iqr(data, column2plot_neomel, k=outlier_tolerance_k, outlier_col='outlier', verbose=True)
filtered_data_neomel = data_labeled_neomel[~data_labeled_neomel['outlier']]

# Plot before and after
fig, axes = plt.subplots(ncols=2)
data[column2plot_neomel].plot.box(ax=axes[0])
filtered_data_neomel[column2plot_neomel].plot.box(ax=axes[1])
axes[0].title.set_text("Before Filtering")
axes[1].title.set_text("After Filtering")
plt.show()

filtered_Y_neomel = filtered_data_neomel.iloc[:,12:]
print(filtered_Y_neomel)

filtered_y1_neomel = filtered_Y_neomel['neomel']
print(filtered_y1_neomel)

plt.hist(filtered_y1_neomel, bins=100)

plt.show()
print(filtered_y1_neomel.max)

print(filtered_data_neomel)
filtered_x_neomel = filtered_data_neomel.iloc[:,3:12]
print(filtered_x_neomel)
print(filtered_y1_neomel)

from sklearn.model_selection import train_test_split
x_train_neomel, x_test_neomel, y_train_neomel, y_test_neomel = train_test_split(filtered_x_neomel, filtered_y1_neomel, test_size = 0.2, random_state = 0)
print(y_test_neomel)
print(y_train_neomel)
print(x_train_neomel)
print(x_test_neomel)

clf_neomel = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_neomel.fit(x_train_neomel, y_train_neomel)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_neomel = clf_neomel.predict(x_test_neomel)
print(y_pred_neomel)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_neomel, y_pred_neomel))
print('MSE: ', mean_squared_error(y_test_neomel, y_pred_neomel))

from sklearn.metrics import r2_score
r2_score(y_test_neomel, y_pred_neomel)

plt.scatter(x_test_neomel['seb, m/s'].values, y_test_neomel, color = 'red')
plt.scatter(x_test_neomel['seb, m/s'].values, y_pred_neomel, color = 'green')
plt.title('Random Forest Regression')
plt.xlabel('seb, m/s')
plt.ylabel('Neomel')
plt.show()

plt.scatter(x_test_neomel['mélység, m'].values, y_test_neomel, color = 'red')
plt.scatter(x_test_neomel['mélység, m'].values, y_pred_neomel, color = 'green')
plt.title('Random Forest Regression')
plt.xlabel('mélység, m')
plt.ylabel('Neomel')
plt.show()

plt.scatter(y_test_neomel, y_pred_neomel, color = 'red')

plt.scatter(y_test_neomel, y_pred_neomel-y_test_neomel, color = 'blue')
plt.title('Random Forest Regression - Neomel')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_neomel, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_neomel, y_test_neomel/y_pred_neomel, color = 'green')
plt.title('Random Forest Regression - Neomel')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_neomel = clf_neomel.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_neomel.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_neomel = pd.Series(importances_neomel, index=feature_names)

fig, ax = plt.subplots()
forest_importances_neomel.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(filtered_x_neomel)

for i in range(22):
  fig, ax = plt.subplots()
  Y.iloc[:,i].hist(bins=100, ax=ax)
  ax.annotate('kiugró',
              xy=(Y.iloc[:,i].max()-4, 20),
              xytext=(Y.iloc[:,i].max()-4, 140),
              arrowprops=dict(color='red',width=1),
              horizontalalignment='center',
              size=14)
  plt.show()

"""# **20. Minta egyedszám**



"""

# A minta-egyedszám is szűrt legyen:

column2plot = 'minta-egyedszam'
outlier_tolerance_k = 5 # larger means you tolerate more extreme values. For gaussian data, standard is 1.5.

data_labeled_egyedszam = label_outliers_iqr(data, column2plot, k=outlier_tolerance_k, outlier_col='outlier', verbose=True)
filtered_data_egyedszam = data_labeled_egyedszam[~data_labeled_egyedszam['outlier']]

# Plot before and after
fig, axes = plt.subplots(ncols=2)
data[column2plot].plot.box(ax=axes[0])
filtered_data_egyedszam[column2plot].plot.box(ax=axes[1])
axes[0].title.set_text("Before Filtering")
axes[1].title.set_text("After Filtering")
plt.show()

filtered_Y_egyedszam = filtered_data_egyedszam.iloc[:,12:]
print(filtered_Y_egyedszam)

filtered_y1_egyedszam = filtered_Y_egyedszam['minta-egyedszam']
print(filtered_y1_egyedszam)

plt.hist(filtered_y1_egyedszam , bins=100)

plt.show()
print(filtered_y1_egyedszam .max)

filtered_x_egyedszam = filtered_data_egyedszam.iloc[:,0:1]
print(filtered_x_egyedszam )

print(filtered_data_egyedszam)
filtered_x_egyedszam = filtered_data_egyedszam.iloc[:,3:12]
print(filtered_x_egyedszam)
print(filtered_y1_egyedszam)

from sklearn.model_selection import train_test_split
x_train_egyedszam, x_test_egyedszam, y_train_egyedszam, y_test_egyedszam = train_test_split(filtered_x_egyedszam, filtered_y1_egyedszam, test_size = 0.2, random_state = 0)
print(y_test_egyedszam)
print(y_train_egyedszam)
print(x_train_egyedszam)
print(x_test_egyedszam)

clf_egyedszam = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_egyedszam.fit(x_train_egyedszam, y_train_egyedszam)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_egyedszam = clf_egyedszam.predict(x_test_egyedszam)
print(y_pred_egyedszam)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_egyedszam, y_pred_egyedszam))
print('MSE: ', mean_squared_error(y_test_egyedszam, y_pred_egyedszam))

from sklearn.metrics import r2_score
r2_score(y_test_egyedszam, y_pred_egyedszam)

plt.scatter(y_test_egyedszam, y_pred_egyedszam, color = 'red')

plt.scatter(y_test_egyedszam, y_pred_egyedszam-y_test_egyedszam, color = 'blue')
plt.title('Random Forest Regression - egyedszam')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_egyedszam, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_egyedszam, y_test_egyedszam/y_pred_egyedszam, color = 'green')
plt.title('Random Forest Regression - egyedszam')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_egyedszam = clf_egyedszam.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_egyedszam.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_egyedszam = pd.Series(importances_egyedszam, index=feature_names)

fig, ax = plt.subplots()
forest_importances_egyedszam.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(filtered_x_egyedszam)

import altair as alt

Y.columns

"""# **0. albalb:**



"""

y_albalb = Y.iloc[:,0]
print(y_albalb)
print(x)

plt.hist(y_albalb, bins=100)

plt.show()
print(y_albalb.max)

from sklearn.model_selection import train_test_split
x_train_albalb, x_test_albalb, y_train_albalb, y_test_albalb = train_test_split(x, y_albalb, test_size = 0.2, random_state = 0)
print(y_test_albalb)
print(y_train_albalb)
print(x_train_albalb)
print(x_test_albalb)

clf_albalb = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_albalb.fit(x_train_albalb, y_train_albalb)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_albalb = clf_albalb.predict(x_test_albalb)
print(y_pred_albalb)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_albalb, y_pred_albalb))
print('MSE: ', mean_squared_error(y_test_albalb, y_pred_albalb))

from sklearn.metrics import r2_score
r2_score(y_test_albalb, y_pred_albalb)

plt.scatter(x_test_albalb['seb, m/s'].values, y_test_albalb, color = 'red')
plt.scatter(x_test_albalb['seb, m/s'].values, y_pred_albalb, color = 'green')
plt.title('Random Forest Regression')
plt.xlabel('seb, m/s')
plt.ylabel('Neomel')
plt.show()

plt.scatter(x_test_albalb['mélység, m'].values, y_test_albalb, color = 'red')
plt.scatter(x_test_albalb['mélység, m'].values, y_pred_albalb, color = 'green')
plt.title('Random Forest Regression')
plt.xlabel('mélység, m')
plt.ylabel('Neomel')
plt.show()

plt.scatter(y_test_albalb, y_pred_albalb, color = 'red')

plt.scatter(y_test_albalb, y_pred_albalb-y_test_albalb, color = 'blue')
plt.title('Random Forest Regression - albalb')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_albalb, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_albalb, y_test_albalb/y_pred_albalb, color = 'green')
plt.title('Random Forest Regression - albalb')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_albalb = clf_albalb.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_albalb.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_albalb = pd.Series(importances_albalb, index=feature_names)

fig, ax = plt.subplots()
forest_importances_albalb.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)

"""# **1. blibjo:**



"""

y_blibjo = Y.iloc[:,1]
print(y_blibjo)
print(x)

plt.hist(y_blibjo, bins=100)

plt.show()
print(y_blibjo.max)

from sklearn.model_selection import train_test_split
x_train_blibjo, x_test_blibjo, y_train_blibjo, y_test_blibjo = train_test_split(x, y_blibjo, test_size = 0.2, random_state = 0)
print(y_test_blibjo)
print(y_train_blibjo)
print(x_train_blibjo)
print(x_test_blibjo)

clf_blibjo = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_blibjo.fit(x_train_blibjo, y_train_blibjo)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_blibjo = clf_blibjo.predict(x_test_blibjo)
print(y_pred_blibjo)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_blibjo, y_pred_blibjo))
print('MSE: ', mean_squared_error(y_test_blibjo, y_pred_blibjo))

from sklearn.metrics import r2_score
r2_score(y_test_blibjo, y_pred_blibjo)

plt.scatter(y_test_blibjo, y_pred_blibjo, color = 'red')

plt.scatter(y_test_blibjo, y_pred_blibjo-y_test_blibjo, color = 'blue')
plt.title('Random Forest Regression - albalb')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_blibjo, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_blibjo, y_test_blibjo/y_pred_blibjo, color = 'green')
plt.title('Random Forest Regression - blibjo')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_blibjo = clf_blibjo.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_blibjo.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_blibjo = pd.Series(importances_blibjo, index=feature_names)

fig, ax = plt.subplots()
forest_importances_blibjo.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)

"""# **2. chonas:**



"""

y_chonas = Y.iloc[:,2]
print(y_chonas)
print(x)

plt.hist(y_chonas, bins=100)

plt.show()
print(y_chonas.max)

from sklearn.model_selection import train_test_split
x_train_chonas, x_test_chonas, y_train_chonas, y_test_chonas = train_test_split(x, y_chonas, test_size = 0.2, random_state = 0)
print(y_test_chonas)
print(y_train_chonas)
print(x_train_chonas)
print(x_test_chonas)

clf_chonas = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_chonas.fit(x_train_chonas, y_train_chonas)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_chonas = clf_chonas.predict(x_test_chonas)
print(y_pred_chonas)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_chonas, y_pred_chonas))
print('MSE: ', mean_squared_error(y_test_chonas, y_pred_chonas))

from sklearn.metrics import r2_score
r2_score(y_test_chonas, y_pred_chonas)

plt.scatter(y_test_chonas, y_pred_chonas, color = 'red')

plt.scatter(y_test_chonas, y_pred_chonas-y_test_chonas, color = 'blue')
plt.title('Random Forest Regression - chonas')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_blibjo, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_chonas, y_test_chonas/y_pred_chonas, color = 'green')
plt.title('Random Forest Regression - chonas')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_chonas = clf_chonas.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_chonas.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_chonas = pd.Series(importances_chonas, index=feature_names)

fig, ax = plt.subplots()
forest_importances_chonas.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)

"""# **3. gymsch:**



"""

y_gymsch = Y.iloc[:,3]
print(y_gymsch)
print(x)

plt.hist(y_gymsch, bins=100)

plt.show()
print(y_gymsch.max)

from sklearn.model_selection import train_test_split
x_train_gymsch, x_test_gymsch, y_train_gymsch, y_test_gymsch = train_test_split(x, y_gymsch, test_size = 0.2, random_state = 0)
print(y_test_gymsch)
print(y_train_gymsch)
print(x_train_gymsch)
print(x_test_gymsch)

clf_gymsch = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_gymsch.fit(x_train_gymsch, y_train_gymsch)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_gymsch = clf_gymsch.predict(x_test_gymsch)
print(y_pred_gymsch)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_gymsch, y_pred_gymsch))
print('MSE: ', mean_squared_error(y_test_gymsch, y_pred_gymsch))

from sklearn.metrics import r2_score
r2_score(y_test_gymsch, y_pred_gymsch)

plt.scatter(y_test_gymsch, y_pred_gymsch, color = 'red')

plt.scatter(y_test_gymsch, y_pred_gymsch-y_test_gymsch, color = 'blue')
plt.title('Random Forest Regression - gymsch')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_gymsch, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_gymsch, y_test_chonas/y_pred_gymsch, color = 'green')
plt.title('Random Forest Regression - gymsch')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_gymsch = clf_gymsch.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_gymsch.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_gymsch = pd.Series(importances_gymsch, index=feature_names)

fig, ax = plt.subplots()
forest_importances_gymsch.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)



"""# **4. leuasp:**



"""

y_leuasp = Y.iloc[:,4]
print(y_leuasp)
print(x)

plt.hist(y_leuasp, bins=100)

plt.show()
print(y_leuasp.max)

from sklearn.model_selection import train_test_split
x_train_leuasp, x_test_leuasp, y_train_leuasp, y_test_leuasp = train_test_split(x, y_leuasp, test_size = 0.2, random_state = 0)
print(y_test_leuasp)
print(y_train_leuasp)
print(x_train_leuasp)
print(x_test_leuasp)

clf_leuasp = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_leuasp.fit(x_train_leuasp, y_train_leuasp)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_leuasp = clf_leuasp.predict(x_test_leuasp)
print(y_pred_leuasp)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_leuasp, y_pred_leuasp))
print('MSE: ', mean_squared_error(y_test_leuasp, y_pred_leuasp))

from sklearn.metrics import r2_score
r2_score(y_test_leuasp, y_pred_leuasp)

plt.scatter(y_test_leuasp, y_pred_leuasp, color = 'red')

plt.scatter(y_test_leuasp, y_pred_leuasp-y_test_leuasp, color = 'blue')
plt.title('Random Forest Regression - leuasp')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_leuasp, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_leuasp, y_test_leuasp/y_pred_leuasp, color = 'green')
plt.title('Random Forest Regression - leuasp')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_leuasp = clf_leuasp.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_leuasp.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_leuasp = pd.Series(importances_leuasp, index=feature_names)

fig, ax = plt.subplots()
forest_importances_leuasp.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)





"""# **5. leuidu:**



"""

y_leuidu = Y.iloc[:,5]
print(y_leuidu)
print(x)

plt.hist(y_leuidu, bins=100)

plt.show()
print(y_leuidu.max)

from sklearn.model_selection import train_test_split
x_train_leuidu, x_test_leuidu, y_train_leuidu, y_test_leuidu = train_test_split(x, y_leuidu, test_size = 0.2, random_state = 0)
print(y_test_leuidu)
print(y_train_leuidu)
print(x_train_leuidu)
print(x_test_leuidu)

clf_leuidu = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_leuidu.fit(x_train_leuidu, y_train_leuidu)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_leuidu = clf_leuidu.predict(x_test_leuasp)
print(y_pred_leuidu)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_leuasp, y_pred_leuidu))
print('MSE: ', mean_squared_error(y_test_leuasp, y_pred_leuidu))

from sklearn.metrics import r2_score
r2_score(y_test_leuidu, y_pred_leuidu)

plt.scatter(y_test_leuidu, y_pred_leuidu, color = 'red')

plt.scatter(y_test_leuidu, y_pred_leuidu-y_test_leuidu, color = 'blue')
plt.title('Random Forest Regression - leuidu')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_leuidu, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_leuidu, y_test_leuidu/y_pred_leuidu, color = 'green')
plt.title('Random Forest Regression - leuidu')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_leuidu = clf_leuidu.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_leuasp.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_leuidu = pd.Series(importances_leuidu, index=feature_names)

fig, ax = plt.subplots()
forest_importances_leuidu.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)



"""# **6. lotlot:**



"""

y_lotlot = Y.iloc[:,6]
print(y_lotlot)
print(x)

plt.hist(y_lotlot, bins=100)

plt.show()
print(y_lotlot.max)

from sklearn.model_selection import train_test_split
x_train_lotlot, x_test_lotlot, y_train_lotlot, y_test_lotlot = train_test_split(x, y_lotlot, test_size = 0.2, random_state = 0)
print(y_test_lotlot)
print(y_train_lotlot)
print(x_train_lotlot)
print(x_test_lotlot)

clf_lotlot = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_lotlot.fit(x_train_lotlot, y_train_lotlot)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_lotlot = clf_lotlot.predict(x_test_lotlot)
print(y_pred_lotlot)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_leuasp, y_pred_lotlot))
print('MSE: ', mean_squared_error(y_test_lotlot, y_pred_lotlot))

from sklearn.metrics import r2_score
r2_score(y_test_lotlot, y_pred_lotlot)

plt.scatter(y_test_lotlot, y_pred_lotlot, color = 'red')

plt.scatter(y_test_lotlot, y_pred_lotlot-y_test_lotlot, color = 'blue')
plt.title('Random Forest Regression - lotlot')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_lotlot, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_lotlot, y_test_lotlot/y_pred_lotlot, color = 'green')
plt.title('Random Forest Regression - lotlot')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_lotlot = clf_lotlot.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_lotlot.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_lotlot = pd.Series(importances_lotlot, index=feature_names)

fig, ax = plt.subplots()
forest_importances_lotlot.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)



"""# **7. neoflu:**



"""

y_neoflu = Y.iloc[:,7]
print(y_neoflu)
print(x)

plt.hist(y_neoflu, bins=100)

plt.show()
print(y_neoflu.max)

from sklearn.model_selection import train_test_split
x_train_neoflu, x_test_neoflu, y_train_neoflu, y_test_neoflu = train_test_split(x, y_neoflu, test_size = 0.2, random_state = 0)
print(y_test_neoflu)
print(y_train_neoflu)
print(x_train_neoflu)
print(x_test_neoflu)

clf_neoflu = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_neoflu.fit(x_train_neoflu, y_train_neoflu)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_neoflu = clf_neoflu.predict(x_test_neoflu)
print(y_pred_neoflu)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_neoflu, y_pred_neoflu))
print('MSE: ', mean_squared_error(y_test_neoflu, y_pred_neoflu))

from sklearn.metrics import r2_score
r2_score(y_test_neoflu, y_pred_neoflu)

plt.scatter(y_test_lotlot, y_pred_lotlot, color = 'red')

plt.scatter(y_test_neoflu, y_pred_neoflu-y_test_neoflu, color = 'blue')
plt.title('Random Forest Regression - neoflu')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_lotlot, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_neoflu, y_test_neoflu/y_pred_neoflu, color = 'green')
plt.title('Random Forest Regression - neoflu')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_neoflu = clf_neoflu.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_neoflu.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_neoflu = pd.Series(importances_neoflu, index=feature_names)

fig, ax = plt.subplots()
forest_importances_neoflu.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)

impod = (forest_importances_albalb, forest_importances_blibjo, forest_importances_chonas, forest_importances_gymsch, forest_importances_leuasp, forest_importances_leuidu, forest_importances_lotlot, forest_importances_neoflu, forest_importances_neomel, forest_importances_egyedszam)
print(impod)
print(impod[1])



"""# **9. perflu:**



"""

y_perflu = Y.iloc[:,9]
print(y_perflu)
print(x)

plt.hist(y_perflu, bins=100)

plt.show()
print(y_perflu.max)

from sklearn.model_selection import train_test_split
x_train_perflu, x_test_perflu, y_train_perflu, y_test_perflu = train_test_split(x, y_perflu, test_size = 0.2, random_state = 0)
print(y_test_perflu)
print(y_train_perflu)
print(x_train_perflu)
print(x_test_perflu)

clf_perflu = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_perflu.fit(x_train_perflu, y_train_perflu)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_perflu = clf_perflu.predict(x_test_perflu)
print(y_pred_perflu)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_perflu, y_pred_perflu))
print('MSE: ', mean_squared_error(y_test_perflu, y_pred_perflu))

from sklearn.metrics import r2_score
r2_score(y_test_perflu, y_pred_perflu)

plt.scatter(y_test_perflu, y_pred_perflu, color = 'red')

plt.scatter(y_test_perflu, y_pred_perflu-y_test_perflu, color = 'blue')
plt.title('Random Forest Regression - perflu')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_perflu, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_perflu, y_test_perflu/y_pred_perflu, color = 'green')
plt.title('Random Forest Regression - perflu')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_perflu = clf_perflu.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_perflu.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_perflu = pd.Series(importances_perflu, index=feature_names)

fig, ax = plt.subplots()
forest_importances_perflu.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)



"""# **10. ponkes:**



"""

y_ponkes = Y.iloc[:,10]
print(y_ponkes)
print(x)

plt.hist(y_ponkes, bins=100)

plt.show()
print(y_ponkes.max)

from sklearn.model_selection import train_test_split
x_train_ponkes, x_test_ponkes, y_train_ponkes, y_test_ponkes = train_test_split(x, y_ponkes, test_size = 0.2, random_state = 0)
print(y_test_ponkes)
print(y_train_ponkes)
print(x_train_ponkes)
print(x_test_ponkes)

clf_ponkes = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_ponkes.fit(x_train_ponkes, y_train_ponkes)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_ponkes = clf_ponkes.predict(x_test_ponkes)
print(y_pred_ponkes)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_ponkes, y_pred_ponkes))
print('MSE: ', mean_squared_error(y_test_ponkes, y_pred_ponkes))

from sklearn.metrics import r2_score
r2_score(y_test_ponkes, y_pred_ponkes)

plt.scatter(y_test_ponkes, y_pred_ponkes, color = 'red')

plt.scatter(y_test_ponkes, y_pred_ponkes-y_test_ponkes, color = 'blue')
plt.title('Random Forest Regression - ponkes')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_ponkes, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_ponkes, y_test_ponkes/y_pred_ponkes, color = 'green')
plt.title('Random Forest Regression - ponkes')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_ponkes = clf_ponkes.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_ponkes.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_ponkes = pd.Series(importances_ponkes, index=feature_names)

fig, ax = plt.subplots()
forest_importances_ponkes.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)

"""# **11. romvla:**



"""

y_romvla = Y.iloc[:,11]
print(y_romvla)
print(x)

plt.hist(y_romvla, bins=100)

plt.show()
print(y_romvla.max)

from sklearn.model_selection import train_test_split
x_train_romvla, x_test_romvla, y_train_romvla, y_test_romvla = train_test_split(x, y_romvla, test_size = 0.2, random_state = 0)
print(y_test_romvla)
print(y_train_romvla)
print(x_train_romvla)
print(x_test_romvla)

clf_romvla = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_romvla.fit(x_train_romvla, y_train_romvla)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_romvla = clf_romvla.predict(x_test_neoflu)
print(y_pred_romvla)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_romvla, y_pred_romvla))
print('MSE: ', mean_squared_error(y_test_romvla, y_pred_romvla))

from sklearn.metrics import r2_score
r2_score(y_test_romvla, y_pred_romvla)

plt.scatter(y_test_romvla, y_pred_romvla, color = 'red')

plt.scatter(y_test_romvla, y_pred_romvla-y_test_romvla, color = 'blue')
plt.title('Random Forest Regression - romvla')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_romvla, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_romvla, y_test_romvla/y_pred_romvla, color = 'green')
plt.title('Random Forest Regression - romvla')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_romvla = clf_romvla.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_romvla.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_romvla = pd.Series(importances_romvla, index=feature_names)

fig, ax = plt.subplots()
forest_importances_romvla.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)

"""#**12. rutrut:**"""

y_rutrut = Y.iloc[:,12]
print(y_rutrut)
print(x)

plt.hist(y_rutrut, bins=100)

plt.show()
print(y_rutrut.max)

from sklearn.model_selection import train_test_split
x_train_rutrut, x_test_rutrut, y_train_rutrut, y_test_rutrut = train_test_split(x, y_rutrut, test_size = 0.2, random_state = 0)
print(y_test_rutrut)
print(y_train_rutrut)
print(x_train_rutrut)
print(x_test_rutrut)

clf_rutrut = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_rutrut.fit(x_train_rutrut, y_train_rutrut)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_rutrut = clf_rutrut.predict(x_test_rutrut)
print(y_pred_rutrut)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_rutrut, y_pred_rutrut))
print('MSE: ', mean_squared_error(y_test_rutrut, y_pred_rutrut))

from sklearn.metrics import r2_score
r2_score(y_test_rutrut, y_pred_rutrut)

plt.scatter(y_test_rutrut, y_pred_rutrut, color = 'red')

plt.scatter(y_test_rutrut, y_pred_rutrut-y_test_rutrut, color = 'blue')
plt.title('Random Forest Regression - rutrut')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_rutrut, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_rutrut, y_test_rutrut/y_pred_rutrut, color = 'green')
plt.title('Random Forest Regression - rutrut')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_rutrut = clf_rutrut.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_rutrut.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_rutrut = pd.Series(importances_rutrut, index=feature_names)

fig, ax = plt.subplots()
forest_importances_rutrut.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)

"""#**13. rutvir:**"""

y_rutvir = Y.iloc[:,13]
print(y_rutvir)
print(x)

plt.hist(y_rutvir, bins=100)

plt.show()
print(y_rutvir.max)

from sklearn.model_selection import train_test_split
x_train_rutvir, x_test_rutvir, y_train_rutvir, y_test_rutvir = train_test_split(x, y_rutvir, test_size = 0.2, random_state = 0)
print(y_test_rutvir)
print(y_train_rutvir)
print(x_train_rutvir)
print(x_test_rutvir)

clf_rutvir = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_rutvir.fit(x_train_rutvir, y_train_rutvir)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_rutvir = clf_rutvir.predict(x_test_rutvir)
print(y_pred_rutvir)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_rutvir, y_pred_rutvir))
print('MSE: ', mean_squared_error(y_test_rutvir, y_pred_rutvir))

from sklearn.metrics import r2_score
r2_score(y_test_rutvir, y_pred_rutvir)

plt.scatter(y_test_rutvir, y_pred_rutvir, color = 'red')

plt.scatter(y_test_rutvir, y_pred_rutvir-y_test_rutvir, color = 'blue')
plt.title('Random Forest Regression - rutvir')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_rutvir, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_rutvir, y_test_rutvir/y_pred_rutvir, color = 'green')
plt.title('Random Forest Regression - rutvir')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_rutvir = clf_rutvir.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_rutvir.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_rutvir = pd.Series(importances_rutvir, index=feature_names)

fig, ax = plt.subplots()
forest_importances_rutvir.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)

"""#**14. sanluc:**"""

y_sanluc = Y.iloc[:,14]
print(y_sanluc)
print(x)

plt.hist(y_sanluc, bins=100)

plt.show()
print(y_sanluc.max)

from sklearn.model_selection import train_test_split
x_train_sanluc, x_test_sanluc, y_train_sanluc, y_test_sanluc = train_test_split(x, y_sanluc, test_size = 0.2, random_state = 0)
print(y_test_sanluc)
print(y_train_sanluc)
print(x_train_sanluc)
print(x_test_sanluc)

clf_sanluc = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_sanluc.fit(x_train_sanluc, y_train_sanluc)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_sanluc = clf_sanluc.predict(x_test_sanluc)
print(y_pred_sanluc)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_sanluc, y_pred_sanluc))
print('MSE: ', mean_squared_error(y_test_sanluc, y_pred_sanluc))

from sklearn.metrics import r2_score
r2_score(y_test_sanluc, y_pred_sanluc)

plt.scatter(y_test_sanluc, y_pred_sanluc, color = 'red')

plt.scatter(y_test_sanluc, y_pred_sanluc-y_test_sanluc, color = 'blue')
plt.title('Random Forest Regression - sanluc')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_sanluc, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_sanluc, y_test_sanluc/y_pred_sanluc, color = 'green')
plt.title('Random Forest Regression - sanluc')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_sanluc = clf_sanluc.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_sanluc.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_sanluc = pd.Series(importances_sanluc, index=feature_names)

fig, ax = plt.subplots()
forest_importances_sanluc.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)

"""#**15. sanvol:**"""

y_sanvol = Y.iloc[:,15]
print(y_sanvol)
print(x)

plt.hist(y_sanvol, bins=100)

plt.show()
print(y_sanvol.max)

from sklearn.model_selection import train_test_split
x_train_sanvol, x_test_sanvol, y_train_sanvol, y_test_sanvol = train_test_split(x, y_sanvol, test_size = 0.2, random_state = 0)
print(y_test_sanvol)
print(y_train_sanvol)
print(x_train_sanvol)
print(x_test_sanvol)

clf_sanvol = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_sanvol.fit(x_train_sanvol, y_train_sanvol)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_sanvol = clf_sanvol.predict(x_test_sanvol)
print(y_pred_sanvol)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_sanvol, y_pred_sanvol))
print('MSE: ', mean_squared_error(y_test_sanvol, y_pred_sanvol))

from sklearn.metrics import r2_score
r2_score(y_test_sanvol, y_pred_sanvol)

plt.scatter(y_test_sanvol, y_pred_sanvol, color = 'red')

plt.scatter(y_test_sanvol, y_pred_sanvol-y_test_sanvol, color = 'blue')
plt.title('Random Forest Regression - sanvol')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_sanvol, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_sanvol, y_test_sanvol/y_pred_sanvol, color = 'green')
plt.title('Random Forest Regression - sanvol')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_sanvol = clf_sanvol.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_sanvol.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_sanvol = pd.Series(importances_sanvol, index=feature_names)

fig, ax = plt.subplots()
forest_importances_sanvol.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)

"""#**16. squcep:**"""

y_squcep = Y.iloc[:,16]
print(y_squcep)
print(x)

plt.hist(y_squcep, bins=100)

plt.show()
print(y_squcep.max)

from sklearn.model_selection import train_test_split
x_train_squcep, x_test_squcep, y_train_squcep, y_test_squcep = train_test_split(x, y_squcep, test_size = 0.2, random_state = 0)
print(y_test_squcep)
print(y_train_squcep)
print(x_train_squcep)
print(x_test_squcep)

clf_squcep = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_squcep.fit(x_train_squcep, y_train_squcep)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_squcep = clf_squcep.predict(x_test_squcep)
print(y_pred_squcep)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_squcep, y_pred_squcep))
print('MSE: ', mean_squared_error(y_test_squcep, y_pred_squcep))

from sklearn.metrics import r2_score
r2_score(y_test_squcep, y_pred_squcep)

plt.scatter(y_test_squcep, y_pred_squcep, color = 'red')

plt.scatter(y_test_squcep, y_pred_squcep-y_test_squcep, color = 'blue')
plt.title('Random Forest Regression - squcep')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_squcep, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_squcep, y_test_squcep/y_pred_squcep, color = 'green')
plt.title('Random Forest Regression - squcep')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_squcep = clf_squcep.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_squcep.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_squcep = pd.Series(importances_squcep, index=feature_names)

fig, ax = plt.subplots()
forest_importances_squcep.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)

"""#**17. vimvim:**"""

y_vimvim = Y.iloc[:,17]
print(y_vimvim)
print(x)

plt.hist(y_vimvim, bins=100)

plt.show()
print(y_vimvim.max)

from sklearn.model_selection import train_test_split
x_train_vimvim, x_test_vimvim, y_train_vimvim, y_test_vimvim = train_test_split(x, y_vimvim, test_size = 0.2, random_state = 0)
print(y_test_vimvim)
print(y_train_vimvim)
print(x_train_vimvim)
print(x_test_vimvim)

clf_vimvim = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_vimvim.fit(x_train_vimvim, y_train_vimvim)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_vimvim = clf_vimvim.predict(x_test_vimvim)
print(y_pred_vimvim)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_vimvim, y_pred_vimvim))
print('MSE: ', mean_squared_error(y_test_vimvim, y_pred_vimvim))

from sklearn.metrics import r2_score
r2_score(y_test_vimvim, y_pred_vimvim)

plt.scatter(y_test_vimvim, y_pred_vimvim, color = 'red')

plt.scatter(y_test_vimvim, y_pred_vimvim-y_test_vimvim, color = 'blue')
plt.title('Random Forest Regression - vimvim')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_vimvim, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_vimvim, y_test_vimvim/y_pred_vimvim, color = 'green')
plt.title('Random Forest Regression - vimvim')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_vimvim = clf_vimvim.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_vimvim.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_vimvim = pd.Series(importances_vimvim, index=feature_names)

fig, ax = plt.subplots()
forest_importances_vimvim.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)



"""#**18. zinstr:**"""

y_zinstr = Y.iloc[:,18]
print(y_zinstr)
print(x)

plt.hist(y_zinstr, bins=100)

plt.show()
print(y_zinstr.max)

from sklearn.model_selection import train_test_split
x_train_zinstr, x_test_zinstr, y_train_zinstr, y_test_zinstr = train_test_split(x, y_zinstr, test_size = 0.2, random_state = 0)
print(y_test_zinstr)
print(y_train_zinstr)
print(x_train_zinstr)
print(x_test_zinstr)

clf_zinstr = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_zinstr.fit(x_train_zinstr, y_train_zinstr)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_zinstr = clf_zinstr.predict(x_test_zinstr)
print(y_pred_zinstr)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_zinstr, y_pred_zinstr))
print('MSE: ', mean_squared_error(y_test_zinstr, y_pred_zinstr))

from sklearn.metrics import r2_score
r2_score(y_test_zinstr, y_pred_zinstr)

plt.scatter(y_test_zinstr, y_pred_zinstr, color = 'red')

plt.scatter(y_test_zinstr, y_pred_zinstr-y_test_zinstr, color = 'blue')
plt.title('Random Forest Regression - zinstr')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_zinstr, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_zinstr, y_test_zinstr/y_pred_zinstr, color = 'green')
plt.title('Random Forest Regression - zinstr')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_zinstr = clf_zinstr.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_zinstr.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_zinstr = pd.Series(importances_zinstr, index=feature_names)

fig, ax = plt.subplots()
forest_importances_zinstr.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)



"""#**19. zinzin:**"""

y_zinzin = Y.iloc[:,19]
print(y_zinzin)
print(x)

plt.hist(y_zinzin, bins=100)

plt.show()
print(y_zinzin.max)

from sklearn.model_selection import train_test_split
x_train_zinzin, x_test_zinzin, y_train_zinzin, y_test_zinzin = train_test_split(x, y_zinzin, test_size = 0.2, random_state = 0)
print(y_test_zinzin)
print(y_train_zinzin)
print(x_train_zinzin)
print(x_test_zinzin)

clf_zinzin = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_zinzin.fit(x_train_zinzin, y_train_zinzin)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_zinzin = clf_zinzin.predict(x_test_zinzin)
print(y_pred_zinzin)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_zinzin, y_pred_zinzin))
print('MSE: ', mean_squared_error(y_test_zinzin, y_pred_zinzin))

from sklearn.metrics import r2_score
r2_score(y_test_zinzin, y_pred_zinzin)

plt.scatter(y_test_zinzin, y_pred_zinzin, color = 'red')

plt.scatter(y_test_zinzin, y_pred_zinzin-y_test_zinzin, color = 'blue')
plt.title('Random Forest Regression - zinzin')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_zinzin, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_zinzin, y_test_zinzin/y_pred_zinzin, color = 'green')
plt.title('Random Forest Regression - zinzin')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_zinzin = clf_zinzin.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_zinzin.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_zinzin = pd.Series(importances_zinzin, index=feature_names)

fig, ax = plt.subplots()
forest_importances_zinzin.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)



"""#**21. minta-fajszam:**"""

y_fajszam = Y.iloc[:,21]
print(y_fajszam)
print(x)

plt.hist(y_fajszam, bins=100)

plt.show()
print(y_fajszam.max)

from sklearn.model_selection import train_test_split
x_train_fajszam, x_test_fajszam, y_train_fajszam, y_test_fajszam = train_test_split(x, y_fajszam, test_size = 0.2, random_state = 0)
print(y_test_fajszam)
print(y_train_fajszam)
print(x_train_fajszam)
print(x_test_fajszam)

clf_fajszam = RandomForestRegressor(n_estimators = 150, max_depth = 5, random_state = 1)
clf_fajszam.fit(x_train_fajszam, y_train_fajszam)
#ki kell hagyni az első oszlopot (főág_mellékág). Valószínűleg zavarja, hogy végig ugyanaz az érték: 1. Így nem is számít, ha kihagyjuk.

y_pred_fajszam = clf_fajszam.predict(x_test_fajszam)
print(y_pred_fajszam)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
print('MAE: ', mean_absolute_error(y_test_fajszam, y_pred_fajszam))
print('MSE: ', mean_squared_error(y_test_fajszam, y_pred_fajszam))

from sklearn.metrics import r2_score
r2_score(y_test_fajszam, y_pred_fajszam)

plt.scatter(y_test_fajszam, y_pred_fajszam, color = 'red')

plt.scatter(y_test_fajszam, y_pred_fajszam-y_test_fajszam, color = 'blue')
plt.title('Random Forest Regression - fajszam')
plt.xlabel('mért db szám')
plt.ylabel('Hiba [delta, mért - pred]')
plt.show()
plt.hist(y_test_fajszam, bins=100)
plt.xlabel('mért db szám')
plt.ylabel('Hisztogram')
plt.show()

plt.scatter(y_test_fajszam, y_test_fajszam/y_pred_fajszam, color = 'green')
plt.title('Random Forest Regression - fajszam')
plt.xlabel('mért db szám')
plt.ylabel('Hiba (arány, y_test/y_pred')
plt.show()

start_time = time.time()
importances_fajszam = clf_fajszam.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_fajszam.estimators_], axis=0)
elapsed_time = time.time() - start_time

print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

feature_names = ["folyoszakasz", "mintaveteliEszkoz","napszak","honap","vizmelyseg","mederanyag","vizallas","vizjaras","sebesseg"]
forest_importances_fajszam = pd.Series(importances_fajszam, index=feature_names)

fig, ax = plt.subplots()
forest_importances_fajszam.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
print(x)

"""# **Összefoglalás**"""

impod = (forest_importances_albalb, forest_importances_blibjo, forest_importances_chonas, forest_importances_gymsch, forest_importances_leuasp, forest_importances_leuidu, forest_importances_lotlot, forest_importances_neoflu, forest_importances_neomel, forest_importances_perflu, forest_importances_ponkes, forest_importances_romvla, forest_importances_rutrut, forest_importances_rutvir, forest_importances_sanluc, forest_importances_sanvol, forest_importances_squcep, forest_importances_vimvim, forest_importances_zinstr, forest_importances_zinzin,forest_importances_egyedszam, forest_importances_fajszam)
print(impod)

df = pd.DataFrame(impod)
print(df)

df.to_csv('importances.csv')
files.download('importances.csv')



"""# **Lekérdezések**

# **1.   tavAp**
"""

tavAp = pd.read_excel( 'tavAp.xlsx')

x_tavAp = tavAp.iloc[:,2:]
print(x_tavAp)

y_pred_tavAp_albalb = clf_albalb.predict(x_tavAp)
y_pred_tavAp_blibjo = clf_blibjo.predict(x_tavAp)
y_pred_tavAp_chonas = clf_chonas.predict(x_tavAp)
y_pred_tavAp_gymsch = clf_gymsch.predict(x_tavAp)
y_pred_tavAp_leuasp = clf_leuasp.predict(x_tavAp)
y_pred_tavAp_leuidu = clf_leuidu.predict(x_tavAp)
y_pred_tavAp_lotlot = clf_lotlot.predict(x_tavAp)
y_pred_tavAp_neoflu = clf_neoflu.predict(x_tavAp)
y_pred_tavAp_neomel = clf_neomel.predict(x_tavAp)
y_pred_tavAp_perflu = clf_perflu.predict(x_tavAp)
y_pred_tavAp_ponkes = clf_ponkes.predict(x_tavAp)
y_pred_tavAp_romvla = clf_romvla.predict(x_tavAp)
y_pred_tavAp_rutrut = clf_rutrut.predict(x_tavAp)
y_pred_tavAp_rutvir = clf_rutvir.predict(x_tavAp)
y_pred_tavAp_sanluc = clf_sanluc.predict(x_tavAp)
y_pred_tavAp_sanvol = clf_sanvol.predict(x_tavAp)
y_pred_tavAp_squcep = clf_squcep.predict(x_tavAp)
y_pred_tavAp_vimvim = clf_vimvim.predict(x_tavAp)
y_pred_tavAp_zinstr = clf_zinstr.predict(x_tavAp)
y_pred_tavAp_zinzin = clf_zinzin.predict(x_tavAp)
y_pred_tavAp_egyedszam = clf_egyedszam.predict(x_tavAp)
y_pred_tavAp_fajszam = clf_fajszam.predict(x_tavAp)

df_albalb = pd.DataFrame(y_pred_tavAp_albalb)
df_albalb.to_csv('y_pred_tavAp_albalb.csv')
files.download('y_pred_tavAp_albalb.csv')

df_blibjo = pd.DataFrame(y_pred_tavAp_blibjo)
df_blibjo.to_csv('y_pred_tavAp_blibjo.csv')
files.download('y_pred_tavAp_blibjo.csv')

df_chonas = pd.DataFrame(y_pred_tavAp_chonas)
df_chonas.to_csv('y_pred_tavAp_chonas.csv')
files.download('y_pred_tavAp_chonas.csv')

df_gymsch = pd.DataFrame(y_pred_tavAp_gymsch)
df_gymsch.to_csv('y_pred_tavAp_gymsch.csv')
files.download('y_pred_tavAp_gymsch.csv')

df_leuasp = pd.DataFrame(y_pred_tavAp_leuasp)
df_leuasp.to_csv('y_pred_tavAp_leuasp.csv')
files.download('y_pred_tavAp_leuasp.csv')

df_leuidu = pd.DataFrame(y_pred_tavAp_leuidu)
df_leuidu.to_csv('y_pred_tavAp_leuidu.csv')
files.download('y_pred_tavAp_leuidu.csv')

df_lotlot = pd.DataFrame(y_pred_tavAp_lotlot)
df_lotlot.to_csv('y_pred_tavAp_lotlot.csv')
files.download('y_pred_tavAp_lotlot.csv')

df_neoflu = pd.DataFrame(y_pred_tavAp_neoflu)
df_neoflu.to_csv('y_pred_tavAp_neoflu.csv')
files.download('y_pred_tavAp_neoflu.csv')

df_neomel = pd.DataFrame(y_pred_tavAp_neomel)
df_neomel.to_csv('y_pred_tavAp_neomel.csv')
files.download('y_pred_tavAp_neomel.csv')

df_perflu = pd.DataFrame(y_pred_tavAp_perflu)
df_perflu.to_csv('y_pred_tavAp_perflu.csv')
files.download('y_pred_tavAp_perflu.csv')

df_ponkes = pd.DataFrame(y_pred_tavAp_ponkes)
df_ponkes.to_csv('y_pred_tavAp_ponkes.csv')
files.download('y_pred_tavAp_ponkes.csv')

df_romvla = pd.DataFrame(y_pred_tavAp_romvla)
df_romvla.to_csv('y_pred_tavAp_romvla.csv')
files.download('y_pred_tavAp_romvla.csv')

df_rutrut = pd.DataFrame(y_pred_tavAp_rutrut)
df_rutrut.to_csv('y_pred_tavAp_rutrut.csv')
files.download('y_pred_tavAp_rutrut.csv')

df_rutvir = pd.DataFrame(y_pred_tavAp_rutvir)
df_rutvir.to_csv('y_pred_tavAp_rutvir.csv')
files.download('y_pred_tavAp_rutvir.csv')

df_sanluc = pd.DataFrame(y_pred_tavAp_sanluc)
df_sanluc.to_csv('y_pred_tavAp_sanluc.csv')
files.download('y_pred_tavAp_sanluc.csv')

df_sanvol = pd.DataFrame(y_pred_tavAp_sanvol)
df_sanvol.to_csv('y_pred_tavAp_sanvol.csv')
files.download('y_pred_tavAp_sanvol.csv')

df_squcep = pd.DataFrame(y_pred_tavAp_squcep)
df_squcep.to_csv('y_pred_tavAp_squcep.csv')
files.download('y_pred_tavAp_squcep.csv')

df_vimvim = pd.DataFrame(y_pred_tavAp_vimvim)
df_vimvim.to_csv('y_pred_tavAp_vimvim.csv')
files.download('y_pred_tavAp_vimvim.csv')

df_zinstr = pd.DataFrame(y_pred_tavAp_zinstr)
df_zinstr.to_csv('y_pred_tavAp_zinstr.csv')
files.download('y_pred_tavAp_zinstr.csv')

df_zinzin = pd.DataFrame(y_pred_tavAp_zinzin)
df_zinzin.to_csv('y_pred_tavAp_zinzin.csv')
files.download('y_pred_tavAp_zinzin.csv')

df_egyedszam = pd.DataFrame(y_pred_tavAp_egyedszam)
df_egyedszam.to_csv('y_pred_tavAp_egyedszam.csv')
files.download('y_pred_tavAp_egyedszam.csv')

df_fajszam = pd.DataFrame(y_pred_tavAp_fajszam)
df_fajszam.to_csv('y_pred_tavAp_fajszam.csv')
files.download('y_pred_tavAp_fajszam.csv')

"""
# **2.   nyarAp**"""

nyarAp = pd.read_excel( 'nyarAp.xlsx')

x_nyarAp = nyarAp.iloc[:,2:]
print(x_nyarAp)

y_pred_nyarAp_albalb = clf_albalb.predict(x_nyarAp)
y_pred_nyarAp_blibjo = clf_blibjo.predict(x_nyarAp)
y_pred_nyarAp_chonas = clf_chonas.predict(x_nyarAp)
y_pred_nyarAp_gymsch = clf_gymsch.predict(x_nyarAp)
y_pred_nyarAp_leuasp = clf_leuasp.predict(x_nyarAp)
y_pred_nyarAp_leuidu = clf_leuidu.predict(x_nyarAp)
y_pred_nyarAp_lotlot = clf_lotlot.predict(x_nyarAp)
y_pred_nyarAp_neoflu = clf_neoflu.predict(x_nyarAp)
y_pred_nyarAp_neomel = clf_neomel.predict(x_nyarAp)
y_pred_nyarAp_perflu = clf_perflu.predict(x_nyarAp)
y_pred_nyarAp_ponkes = clf_ponkes.predict(x_nyarAp)
y_pred_nyarAp_romvla = clf_romvla.predict(x_nyarAp)
y_pred_nyarAp_rutrut = clf_rutrut.predict(x_nyarAp)
y_pred_nyarAp_rutvir = clf_rutvir.predict(x_nyarAp)
y_pred_nyarAp_sanluc = clf_sanluc.predict(x_nyarAp)
y_pred_nyarAp_sanvol = clf_sanvol.predict(x_nyarAp)
y_pred_nyarAp_squcep = clf_squcep.predict(x_nyarAp)
y_pred_nyarAp_vimvim = clf_vimvim.predict(x_nyarAp)
y_pred_nyarAp_zinstr = clf_zinstr.predict(x_nyarAp)
y_pred_nyarAp_zinzin = clf_zinzin.predict(x_nyarAp)
y_pred_nyarAp_egyedszam = clf_egyedszam.predict(x_nyarAp)
y_pred_nyarAp_fajszam = clf_fajszam.predict(x_nyarAp)

df_albalb = pd.DataFrame(y_pred_nyarAp_albalb)
df_albalb.to_csv('y_pred_nyarAp_albalb.csv')
files.download('y_pred_nyarAp_albalb.csv')

df_blibjo = pd.DataFrame(y_pred_nyarAp_blibjo)
df_blibjo.to_csv('y_pred_nyarAp_blibjo.csv')
files.download('y_pred_nyarAp_blibjo.csv')

df_chonas = pd.DataFrame(y_pred_nyarAp_chonas)
df_chonas.to_csv('y_pred_nyarAp_chonas.csv')
files.download('y_pred_nyarAp_chonas.csv')

df_gymsch = pd.DataFrame(y_pred_nyarAp_gymsch)
df_gymsch.to_csv('y_pred_nyarAp_gymsch.csv')
files.download('y_pred_nyarAp_gymsch.csv')

df_leuasp = pd.DataFrame(y_pred_nyarAp_leuasp)
df_leuasp.to_csv('y_pred_nyarAp_leuasp.csv')
files.download('y_pred_nyarAp_leuasp.csv')

df_leuidu = pd.DataFrame(y_pred_nyarAp_leuidu)
df_leuidu.to_csv('y_pred_nyarAp_leuidu.csv')
files.download('y_pred_nyarAp_leuidu.csv')

df_lotlot = pd.DataFrame(y_pred_nyarAp_lotlot)
df_lotlot.to_csv('y_pred_nyarAp_lotlot.csv')
files.download('y_pred_nyarAp_lotlot.csv')

df_neoflu = pd.DataFrame(y_pred_nyarAp_neoflu)
df_neoflu.to_csv('y_pred_nyarAp_neoflu.csv')
files.download('y_pred_nyarAp_neoflu.csv')

df_neomel = pd.DataFrame(y_pred_nyarAp_neomel)
df_neomel.to_csv('y_pred_nyarAp_neomel.csv')
files.download('y_pred_nyarAp_neomel.csv')

df_perflu = pd.DataFrame(y_pred_nyarAp_perflu)
df_perflu.to_csv('y_pred_nyarAp_perflu.csv')
files.download('y_pred_nyarAp_perflu.csv')

df_ponkes = pd.DataFrame(y_pred_nyarAp_ponkes)
df_ponkes.to_csv('y_pred_nyarAp_ponkes.csv')
files.download('y_pred_nyarAp_ponkes.csv')

df_romvla = pd.DataFrame(y_pred_nyarAp_romvla)
df_romvla.to_csv('y_pred_nyarAp_romvla.csv')
files.download('y_pred_nyarAp_romvla.csv')

df_rutrut = pd.DataFrame(y_pred_nyarAp_rutrut)
df_rutrut.to_csv('y_pred_nyarAp_rutrut.csv')
files.download('y_pred_nyarAp_rutrut.csv')

df_rutvir = pd.DataFrame(y_pred_nyarAp_rutvir)
df_rutvir.to_csv('y_pred_nyarAp_rutvir.csv')
files.download('y_pred_nyarAp_rutvir.csv')

df_sanluc = pd.DataFrame(y_pred_nyarAp_sanluc)
df_sanluc.to_csv('y_pred_nyarAp_sanluc.csv')
files.download('y_pred_nyarAp_sanluc.csv')

df_sanvol = pd.DataFrame(y_pred_nyarAp_sanvol)
df_sanvol.to_csv('y_pred_nyarAp_sanvol.csv')
files.download('y_pred_nyarAp_sanvol.csv')

df_squcep = pd.DataFrame(y_pred_nyarAp_squcep)
df_squcep.to_csv('y_pred_nyarAp_squcep.csv')
files.download('y_pred_nyarAp_squcep.csv')

df_vimvim = pd.DataFrame(y_pred_nyarAp_vimvim)
df_vimvim.to_csv('y_pred_nyarAp_vimvim.csv')
files.download('y_pred_nyarAp_vimvim.csv')

df_zinstr = pd.DataFrame(y_pred_nyarAp_zinstr)
df_zinstr.to_csv('y_pred_nyarAp_zinstr.csv')
files.download('y_pred_nyarAp_zinstr.csv')

df_zinzin = pd.DataFrame(y_pred_nyarAp_zinzin)
df_zinzin.to_csv('y_pred_nyarAp_zinzin.csv')
files.download('y_pred_nyarAp_zinzin.csv')

df_egyedszam = pd.DataFrame(y_pred_nyarAp_egyedszam)
df_egyedszam.to_csv('y_pred_nyarAp_egyedszam.csv')
files.download('y_pred_nyarAp_egyedszam.csv')

df_fajszam = pd.DataFrame(y_pred_nyarAp_fajszam)
df_fajszam.to_csv('y_pred_nyarAp_fajszam.csv')
files.download('y_pred_nyarAp_fajszam.csv')

"""
# **3.   oszAp**"""

oszAp = pd.read_excel( 'oszAp.xlsx')

x_oszAp = oszAp.iloc[:,2:]
print(x_oszAp)

y_pred_oszAp_albalb = clf_albalb.predict(x_oszAp)
y_pred_oszAp_blibjo = clf_blibjo.predict(x_oszAp)
y_pred_oszAp_chonas = clf_chonas.predict(x_oszAp)
y_pred_oszAp_gymsch = clf_gymsch.predict(x_oszAp)
y_pred_oszAp_leuasp = clf_leuasp.predict(x_oszAp)
y_pred_oszAp_leuidu = clf_leuidu.predict(x_oszAp)
y_pred_oszAp_lotlot = clf_lotlot.predict(x_oszAp)
y_pred_oszAp_neoflu = clf_neoflu.predict(x_oszAp)
y_pred_oszAp_neomel = clf_neomel.predict(x_oszAp)
y_pred_oszAp_perflu = clf_perflu.predict(x_oszAp)
y_pred_oszAp_ponkes = clf_ponkes.predict(x_oszAp)
y_pred_oszAp_romvla = clf_romvla.predict(x_oszAp)
y_pred_oszAp_rutrut = clf_rutrut.predict(x_oszAp)
y_pred_oszAp_rutvir = clf_rutvir.predict(x_oszAp)
y_pred_oszAp_sanluc = clf_sanluc.predict(x_oszAp)
y_pred_oszAp_sanvol = clf_sanvol.predict(x_oszAp)
y_pred_oszAp_squcep = clf_squcep.predict(x_oszAp)
y_pred_oszAp_vimvim = clf_vimvim.predict(x_oszAp)
y_pred_oszAp_zinstr = clf_zinstr.predict(x_oszAp)
y_pred_oszAp_zinzin = clf_zinzin.predict(x_oszAp)
y_pred_oszAp_egyedszam = clf_egyedszam.predict(x_oszAp)
y_pred_oszAp_fajszam = clf_fajszam.predict(x_oszAp)

df_albalb = pd.DataFrame(y_pred_oszAp_albalb)
df_albalb.to_csv('y_pred_oszAp_albalb.csv')
files.download('y_pred_oszAp_albalb.csv')

df_blibjo = pd.DataFrame(y_pred_oszAp_blibjo)
df_blibjo.to_csv('y_pred_oszAp_blibjo.csv')
files.download('y_pred_oszAp_blibjo.csv')

df_chonas = pd.DataFrame(y_pred_oszAp_chonas)
df_chonas.to_csv('y_pred_oszAp_chonas.csv')
files.download('y_pred_oszAp_chonas.csv')

df_gymsch = pd.DataFrame(y_pred_oszAp_gymsch)
df_gymsch.to_csv('y_pred_oszAp_gymsch.csv')
files.download('y_pred_oszAp_gymsch.csv')

df_leuasp = pd.DataFrame(y_pred_oszAp_leuasp)
df_leuasp.to_csv('y_pred_oszAp_leuasp.csv')
files.download('y_pred_oszAp_leuasp.csv')

df_leuidu = pd.DataFrame(y_pred_oszAp_leuidu)
df_leuidu.to_csv('y_pred_oszAp_leuidu.csv')
files.download('y_pred_oszAp_leuidu.csv')

df_lotlot = pd.DataFrame(y_pred_oszAp_lotlot)
df_lotlot.to_csv('y_pred_oszAp_lotlot.csv')
files.download('y_pred_oszAp_lotlot.csv')

df_neoflu = pd.DataFrame(y_pred_oszAp_neoflu)
df_neoflu.to_csv('y_pred_oszAp_neoflu.csv')
files.download('y_pred_oszAp_neoflu.csv')

df_neomel = pd.DataFrame(y_pred_oszAp_neomel)
df_neomel.to_csv('y_pred_oszAp_neomel.csv')
files.download('y_pred_oszAp_neomel.csv')

df_perflu = pd.DataFrame(y_pred_oszAp_perflu)
df_perflu.to_csv('y_pred_oszAp_perflu.csv')
files.download('y_pred_oszAp_perflu.csv')

df_ponkes = pd.DataFrame(y_pred_oszAp_ponkes)
df_ponkes.to_csv('y_pred_oszAp_ponkes.csv')
files.download('y_pred_oszAp_ponkes.csv')

df_romvla = pd.DataFrame(y_pred_oszAp_romvla)
df_romvla.to_csv('y_pred_oszAp_romvla.csv')
files.download('y_pred_oszAp_romvla.csv')

df_rutrut = pd.DataFrame(y_pred_oszAp_rutrut)
df_rutrut.to_csv('y_pred_oszAp_rutrut.csv')
files.download('y_pred_oszAp_rutrut.csv')

df_rutvir = pd.DataFrame(y_pred_oszAp_rutvir)
df_rutvir.to_csv('y_pred_oszAp_rutvir.csv')
files.download('y_pred_oszAp_rutvir.csv')

df_sanluc = pd.DataFrame(y_pred_oszAp_sanluc)
df_sanluc.to_csv('y_pred_oszAp_sanluc.csv')
files.download('y_pred_oszAp_sanluc.csv')

df_sanvol = pd.DataFrame(y_pred_oszAp_sanvol)
df_sanvol.to_csv('y_pred_oszAp_sanvol.csv')
files.download('y_pred_oszAp_sanvol.csv')

df_squcep = pd.DataFrame(y_pred_oszAp_squcep)
df_squcep.to_csv('y_pred_oszAp_squcep.csv')
files.download('y_pred_oszAp_squcep.csv')

df_vimvim = pd.DataFrame(y_pred_oszAp_vimvim)
df_vimvim.to_csv('y_pred_oszAp_vimvim.csv')
files.download('y_pred_oszAp_vimvim.csv')

df_zinstr = pd.DataFrame(y_pred_oszAp_zinstr)
df_zinstr.to_csv('y_pred_oszAp_zinstr.csv')
files.download('y_pred_oszAp_zinstr.csv')

df_zinzin = pd.DataFrame(y_pred_oszAp_zinzin)
df_zinzin.to_csv('y_pred_oszAp_zinzin.csv')
files.download('y_pred_oszAp_zinzin.csv')

df_egyedszam = pd.DataFrame(y_pred_oszAp_egyedszam)
df_egyedszam.to_csv('y_pred_oszAp_egyedszam.csv')
files.download('y_pred_oszAp_egyedszam.csv')

df_fajszam = pd.DataFrame(y_pred_oszAp_fajszam)
df_fajszam.to_csv('y_pred_oszAp_fajszam.csv')
files.download('y_pred_oszAp_fajszam.csv')



"""
# **4.   tavAr**"""

tavAr = pd.read_excel( 'tavAr.xlsx')

x_tavAr = tavAr.iloc[:,2:]
print(x_tavAr)

y_pred_tavAr_albalb = clf_albalb.predict(x_tavAr)
y_pred_tavAr_blibjo = clf_blibjo.predict(x_tavAr)
y_pred_tavAr_chonas = clf_chonas.predict(x_tavAr)
y_pred_tavAr_gymsch = clf_gymsch.predict(x_tavAr)
y_pred_tavAr_leuasp = clf_leuasp.predict(x_tavAr)
y_pred_tavAr_leuidu = clf_leuidu.predict(x_tavAr)
y_pred_tavAr_lotlot = clf_lotlot.predict(x_tavAr)
y_pred_tavAr_neoflu = clf_neoflu.predict(x_tavAr)
y_pred_tavAr_neomel = clf_neomel.predict(x_tavAr)
y_pred_tavAr_perflu = clf_perflu.predict(x_tavAr)
y_pred_tavAr_ponkes = clf_ponkes.predict(x_tavAr)
y_pred_tavAr_romvla = clf_romvla.predict(x_tavAr)
y_pred_tavAr_rutrut = clf_rutrut.predict(x_tavAr)
y_pred_tavAr_rutvir = clf_rutvir.predict(x_tavAr)
y_pred_tavAr_sanluc = clf_sanluc.predict(x_tavAr)
y_pred_tavAr_sanvol = clf_sanvol.predict(x_tavAr)
y_pred_tavAr_squcep = clf_squcep.predict(x_tavAr)
y_pred_tavAr_vimvim = clf_vimvim.predict(x_tavAr)
y_pred_tavAr_zinstr = clf_zinstr.predict(x_tavAr)
y_pred_tavAr_zinzin = clf_zinzin.predict(x_tavAr)
y_pred_tavAr_egyedszam = clf_egyedszam.predict(x_tavAr)
y_pred_tavAr_fajszam = clf_fajszam.predict(x_tavAr)

df_albalb = pd.DataFrame(y_pred_tavAr_albalb)
df_albalb.to_csv('y_pred_tavAr_albalb.csv')
files.download('y_pred_tavAr_albalb.csv')

df_blibjo = pd.DataFrame(y_pred_tavAr_blibjo)
df_blibjo.to_csv('y_pred_tavAr_blibjo.csv')
files.download('y_pred_tavAr_blibjo.csv')

df_chonas = pd.DataFrame(y_pred_tavAr_chonas)
df_chonas.to_csv('y_pred_tavAr_chonas.csv')
files.download('y_pred_tavAr_chonas.csv')

df_gymsch = pd.DataFrame(y_pred_tavAr_gymsch)
df_gymsch.to_csv('y_pred_tavAr_gymsch.csv')
files.download('y_pred_tavAr_gymsch.csv')

df_leuasp = pd.DataFrame(y_pred_tavAr_leuasp)
df_leuasp.to_csv('y_pred_tavAr_leuasp.csv')
files.download('y_pred_tavAr_leuasp.csv')

df_leuidu = pd.DataFrame(y_pred_tavAr_leuidu)
df_leuidu.to_csv('y_pred_tavAr_leuidu.csv')
files.download('y_pred_tavAr_leuidu.csv')

df_lotlot = pd.DataFrame(y_pred_tavAr_lotlot)
df_lotlot.to_csv('y_pred_tavAr_lotlot.csv')
files.download('y_pred_tavAr_lotlot.csv')

df_neoflu = pd.DataFrame(y_pred_tavAr_neoflu)
df_neoflu.to_csv('y_pred_tavAr_neoflu.csv')
files.download('y_pred_tavAr_neoflu.csv')

df_neomel = pd.DataFrame(y_pred_tavAr_neomel)
df_neomel.to_csv('y_pred_tavAr_neomel.csv')
files.download('y_pred_tavAr_neomel.csv')

df_perflu = pd.DataFrame(y_pred_tavAr_perflu)
df_perflu.to_csv('y_pred_tavAr_perflu.csv')
files.download('y_pred_tavAr_perflu.csv')

df_ponkes = pd.DataFrame(y_pred_tavAr_ponkes)
df_ponkes.to_csv('y_pred_tavAr_ponkes.csv')
files.download('y_pred_tavAr_ponkes.csv')

df_romvla = pd.DataFrame(y_pred_tavAr_romvla)
df_romvla.to_csv('y_pred_tavAr_romvla.csv')
files.download('y_pred_tavAr_romvla.csv')

df_rutrut = pd.DataFrame(y_pred_tavAr_rutrut)
df_rutrut.to_csv('y_pred_tavAr_rutrut.csv')
files.download('y_pred_tavAr_rutrut.csv')

df_rutvir = pd.DataFrame(y_pred_tavAr_rutvir)
df_rutvir.to_csv('y_pred_tavAr_rutvir.csv')
files.download('y_pred_tavAr_rutvir.csv')

df_sanluc = pd.DataFrame(y_pred_tavAr_sanluc)
df_sanluc.to_csv('y_pred_tavAr_sanluc.csv')
files.download('y_pred_tavAr_sanluc.csv')

df_sanvol = pd.DataFrame(y_pred_tavAr_sanvol)
df_sanvol.to_csv('y_pred_tavAr_sanvol.csv')
files.download('y_pred_tavAr_sanvol.csv')

df_squcep = pd.DataFrame(y_pred_tavAr_squcep)
df_squcep.to_csv('y_pred_tavAr_squcep.csv')
files.download('y_pred_tavAr_squcep.csv')

df_vimvim = pd.DataFrame(y_pred_tavAr_vimvim)
df_vimvim.to_csv('y_pred_tavAr_vimvim.csv')
files.download('y_pred_tavAr_vimvim.csv')

df_zinstr = pd.DataFrame(y_pred_tavAr_zinstr)
df_zinstr.to_csv('y_pred_tavAr_zinstr.csv')
files.download('y_pred_tavAr_zinstr.csv')

df_zinzin = pd.DataFrame(y_pred_tavAr_zinzin)
df_zinzin.to_csv('y_pred_tavAr_zinzin.csv')
files.download('y_pred_tavAr_zinzin.csv')

df_egyedszam = pd.DataFrame(y_pred_tavAr_egyedszam)
df_egyedszam.to_csv('y_pred_tavAr_egyedszam.csv')
files.download('y_pred_tavAr_egyedszam.csv')

df_fajszam = pd.DataFrame(y_pred_tavAr_fajszam)
df_fajszam.to_csv('y_pred_tavAr_fajszam.csv')
files.download('y_pred_tavAr_fajszam.csv')

"""
# **5.   oszAr**"""

oszAr = pd.read_excel( 'oszAr.xlsx')
x_oszAr = oszAr.iloc[:,2:]
print(x_oszAr)

y_pred_oszAr_albalb = clf_albalb.predict(x_oszAr)
y_pred_oszAr_blibjo = clf_blibjo.predict(x_oszAr)
y_pred_oszAr_chonas = clf_chonas.predict(x_oszAr)
y_pred_oszAr_gymsch = clf_gymsch.predict(x_oszAr)
y_pred_oszAr_leuasp = clf_leuasp.predict(x_oszAr)
y_pred_oszAr_leuidu = clf_leuidu.predict(x_oszAr)
y_pred_oszAr_lotlot = clf_lotlot.predict(x_oszAr)
y_pred_oszAr_neoflu = clf_neoflu.predict(x_oszAr)
y_pred_oszAr_neomel = clf_neomel.predict(x_oszAr)
y_pred_oszAr_perflu = clf_perflu.predict(x_oszAr)
y_pred_oszAr_ponkes = clf_ponkes.predict(x_oszAr)
y_pred_oszAr_romvla = clf_romvla.predict(x_oszAr)
y_pred_oszAr_rutrut = clf_rutrut.predict(x_oszAr)
y_pred_oszAr_rutvir = clf_rutvir.predict(x_oszAr)
y_pred_oszAr_sanluc = clf_sanluc.predict(x_oszAr)
y_pred_oszAr_sanvol = clf_sanvol.predict(x_oszAr)
y_pred_oszAr_squcep = clf_squcep.predict(x_oszAr)
y_pred_oszAr_vimvim = clf_vimvim.predict(x_oszAr)
y_pred_oszAr_zinstr = clf_zinstr.predict(x_oszAr)
y_pred_oszAr_zinzin = clf_zinzin.predict(x_oszAr)
y_pred_oszAr_egyedszam = clf_egyedszam.predict(x_oszAr)
y_pred_oszAr_fajszam = clf_fajszam.predict(x_oszAr)

df_albalb = pd.DataFrame(y_pred_oszAr_albalb)
df_albalb.to_csv('y_pred_oszAr_albalb.csv')
files.download('y_pred_oszAr_albalb.csv')

df_blibjo = pd.DataFrame(y_pred_oszAr_blibjo)
df_blibjo.to_csv('y_pred_oszAr_blibjo.csv')
files.download('y_pred_oszAr_blibjo.csv')

df_chonas = pd.DataFrame(y_pred_oszAr_chonas)
df_chonas.to_csv('y_pred_oszAr_chonas.csv')
files.download('y_pred_oszAr_chonas.csv')

df_gymsch = pd.DataFrame(y_pred_oszAr_gymsch)
df_gymsch.to_csv('y_pred_oszAr_gymsch.csv')
files.download('y_pred_oszAr_gymsch.csv')

df_leuasp = pd.DataFrame(y_pred_oszAr_leuasp)
df_leuasp.to_csv('y_pred_oszAr_leuasp.csv')
files.download('y_pred_oszAr_leuasp.csv')

df_leuidu = pd.DataFrame(y_pred_oszAr_leuidu)
df_leuidu.to_csv('y_pred_oszAr_leuidu.csv')
files.download('y_pred_oszAr_leuidu.csv')

df_lotlot = pd.DataFrame(y_pred_oszAr_lotlot)
df_lotlot.to_csv('y_pred_oszAr_lotlot.csv')
files.download('y_pred_oszAr_lotlot.csv')

df_neoflu = pd.DataFrame(y_pred_oszAr_neoflu)
df_neoflu.to_csv('y_pred_oszAr_neoflu.csv')
files.download('y_pred_oszAr_neoflu.csv')

df_neomel = pd.DataFrame(y_pred_oszAr_neomel)
df_neomel.to_csv('y_pred_oszAr_neomel.csv')
files.download('y_pred_oszAr_neomel.csv')

df_perflu = pd.DataFrame(y_pred_oszAr_perflu)
df_perflu.to_csv('y_pred_oszAr_perflu.csv')
files.download('y_pred_oszAr_perflu.csv')

df_ponkes = pd.DataFrame(y_pred_oszAr_ponkes)
df_ponkes.to_csv('y_pred_oszAr_ponkes.csv')
files.download('y_pred_oszAr_ponkes.csv')

df_romvla = pd.DataFrame(y_pred_oszAr_romvla)
df_romvla.to_csv('y_pred_oszAr_romvla.csv')
files.download('y_pred_oszAr_romvla.csv')

df_rutrut = pd.DataFrame(y_pred_oszAr_rutrut)
df_rutrut.to_csv('y_pred_oszAr_rutrut.csv')
files.download('y_pred_oszAr_rutrut.csv')

df_rutvir = pd.DataFrame(y_pred_oszAr_rutvir)
df_rutvir.to_csv('y_pred_oszAr_rutvir.csv')
files.download('y_pred_oszAr_rutvir.csv')

df_sanluc = pd.DataFrame(y_pred_oszAr_sanluc)
df_sanluc.to_csv('y_pred_oszAr_sanluc.csv')
files.download('y_pred_oszAr_sanluc.csv')

df_sanvol = pd.DataFrame(y_pred_oszAr_sanvol)
df_sanvol.to_csv('y_pred_oszAr_sanvol.csv')
files.download('y_pred_oszAr_sanvol.csv')

df_squcep = pd.DataFrame(y_pred_oszAr_squcep)
df_squcep.to_csv('y_pred_oszAr_squcep.csv')
files.download('y_pred_oszAr_squcep.csv')

df_vimvim = pd.DataFrame(y_pred_oszAr_vimvim)
df_vimvim.to_csv('y_pred_oszAr_vimvim.csv')
files.download('y_pred_oszAr_vimvim.csv')

df_zinstr = pd.DataFrame(y_pred_oszAr_zinstr)
df_zinstr.to_csv('y_pred_oszAr_zinstr.csv')
files.download('y_pred_oszAr_zinstr.csv')

df_zinzin = pd.DataFrame(y_pred_oszAr_zinzin)
df_zinzin.to_csv('y_pred_oszAr_zinzin.csv')
files.download('y_pred_oszAr_zinzin.csv')

df_egyedszam = pd.DataFrame(y_pred_oszAr_egyedszam)
df_egyedszam.to_csv('y_pred_oszAr_egyedszam.csv')
files.download('y_pred_oszAr_egyedszam.csv')

df_fajszam = pd.DataFrame(y_pred_oszAr_fajszam)
df_fajszam.to_csv('y_pred_oszAr_fajszam.csv')
files.download('y_pred_oszAr_fajszam.csv')

"""
# **6.   nyarAr**"""

nyarAr = pd.read_excel( 'nyarAr.xlsx')
x_nyarAr = nyarAr.iloc[:,2:]
print(x_nyarAr)

y_pred_nyarAr_albalb = clf_albalb.predict(x_nyarAr)
y_pred_nyarAr_blibjo = clf_blibjo.predict(x_nyarAr)
y_pred_nyarAr_chonas = clf_chonas.predict(x_nyarAr)
y_pred_nyarAr_gymsch = clf_gymsch.predict(x_nyarAr)
y_pred_nyarAr_leuasp = clf_leuasp.predict(x_nyarAr)
y_pred_nyarAr_leuidu = clf_leuidu.predict(x_nyarAr)
y_pred_nyarAr_lotlot = clf_lotlot.predict(x_nyarAr)
y_pred_nyarAr_neoflu = clf_neoflu.predict(x_nyarAr)
y_pred_nyarAr_neomel = clf_neomel.predict(x_nyarAr)
y_pred_nyarAr_perflu = clf_perflu.predict(x_nyarAr)
y_pred_nyarAr_ponkes = clf_ponkes.predict(x_nyarAr)
y_pred_nyarAr_romvla = clf_romvla.predict(x_nyarAr)
y_pred_nyarAr_rutrut = clf_rutrut.predict(x_nyarAr)
y_pred_nyarAr_rutvir = clf_rutvir.predict(x_nyarAr)
y_pred_nyarAr_sanluc = clf_sanluc.predict(x_nyarAr)
y_pred_nyarAr_sanvol = clf_sanvol.predict(x_nyarAr)
y_pred_nyarAr_squcep = clf_squcep.predict(x_nyarAr)
y_pred_nyarAr_vimvim = clf_vimvim.predict(x_nyarAr)
y_pred_nyarAr_zinstr = clf_zinstr.predict(x_nyarAr)
y_pred_nyarAr_zinzin = clf_zinzin.predict(x_nyarAr)
y_pred_nyarAr_egyedszam = clf_egyedszam.predict(x_nyarAr)
y_pred_nyarAr_fajszam = clf_fajszam.predict(x_nyarAr)

df_albalb = pd.DataFrame(y_pred_nyarAr_albalb)
df_albalb.to_csv('y_pred_nyarAr_albalb.csv')
files.download('y_pred_nyarAr_albalb.csv')

df_blibjo = pd.DataFrame(y_pred_nyarAr_blibjo)
df_blibjo.to_csv('y_pred_nyarAr_blibjo.csv')
files.download('y_pred_nyarAr_blibjo.csv')

df_chonas = pd.DataFrame(y_pred_nyarAr_chonas)
df_chonas.to_csv('y_pred_nyarAr_chonas.csv')
files.download('y_pred_nyarAr_chonas.csv')

df_gymsch = pd.DataFrame(y_pred_nyarAr_gymsch)
df_gymsch.to_csv('y_pred_nyarAr_gymsch.csv')
files.download('y_pred_nyarAr_gymsch.csv')

df_leuasp = pd.DataFrame(y_pred_nyarAr_leuasp)
df_leuasp.to_csv('y_pred_nyarAr_leuasp.csv')
files.download('y_pred_nyarAr_leuasp.csv')

df_leuidu = pd.DataFrame(y_pred_nyarAr_leuidu)
df_leuidu.to_csv('y_pred_nyarAr_leuidu.csv')
files.download('y_pred_nyarAr_leuidu.csv')

df_lotlot = pd.DataFrame(y_pred_nyarAr_lotlot)
df_lotlot.to_csv('y_pred_nyarAr_lotlot.csv')
files.download('y_pred_nyarAr_lotlot.csv')

df_neoflu = pd.DataFrame(y_pred_nyarAr_neoflu)
df_neoflu.to_csv('y_pred_nyarAr_neoflu.csv')
files.download('y_pred_nyarAr_neoflu.csv')

df_neomel = pd.DataFrame(y_pred_nyarAr_neomel)
df_neomel.to_csv('y_pred_nyarAr_neomel.csv')
files.download('y_pred_nyarAr_neomel.csv')

df_perflu = pd.DataFrame(y_pred_nyarAr_perflu)
df_perflu.to_csv('y_pred_nyarAr_perflu.csv')
files.download('y_pred_nyarAr_perflu.csv')

df_ponkes = pd.DataFrame(y_pred_nyarAr_ponkes)
df_ponkes.to_csv('y_pred_nyarAr_ponkes.csv')
files.download('y_pred_nyarAr_ponkes.csv')

df_romvla = pd.DataFrame(y_pred_nyarAr_romvla)
df_romvla.to_csv('y_pred_nyarAr_romvla.csv')
files.download('y_pred_nyarAr_romvla.csv')

df_rutrut = pd.DataFrame(y_pred_nyarAr_rutrut)
df_rutrut.to_csv('y_pred_nyarAr_rutrut.csv')
files.download('y_pred_nyarAr_rutrut.csv')

df_rutvir = pd.DataFrame(y_pred_nyarAr_rutvir)
df_rutvir.to_csv('y_pred_nyarAr_rutvir.csv')
files.download('y_pred_nyarAr_rutvir.csv')

df_sanluc = pd.DataFrame(y_pred_nyarAr_sanluc)
df_sanluc.to_csv('y_pred_nyarAr_sanluc.csv')
files.download('y_pred_nyarAr_sanluc.csv')

df_sanvol = pd.DataFrame(y_pred_nyarAr_sanvol)
df_sanvol.to_csv('y_pred_nyarAr_sanvol.csv')
files.download('y_pred_nyarAr_sanvol.csv')

df_squcep = pd.DataFrame(y_pred_nyarAr_squcep)
df_squcep.to_csv('y_pred_nyarAr_squcep.csv')
files.download('y_pred_nyarAr_squcep.csv')

df_vimvim = pd.DataFrame(y_pred_nyarAr_vimvim)
df_vimvim.to_csv('y_pred_nyarAr_vimvim.csv')
files.download('y_pred_nyarAr_vimvim.csv')

df_zinstr = pd.DataFrame(y_pred_nyarAr_zinstr)
df_zinstr.to_csv('y_pred_nyarAr_zinstr.csv')
files.download('y_pred_nyarAr_zinstr.csv')

df_zinzin = pd.DataFrame(y_pred_nyarAr_zinzin)
df_zinzin.to_csv('y_pred_nyarAr_zinzin.csv')
files.download('y_pred_nyarAr_zinzin.csv')

df_egyedszam = pd.DataFrame(y_pred_nyarAr_egyedszam)
df_egyedszam.to_csv('y_pred_nyarAr_egyedszam.csv')
files.download('y_pred_nyarAr_egyedszam.csv')

df_fajszam = pd.DataFrame(y_pred_nyarAr_fajszam)
df_fajszam.to_csv('y_pred_nyarAr_fajszam.csv')
files.download('y_pred_nyarAr_fajszam.csv')

df_neomelTestx = pd.DataFrame(x_test_neomel)
df_neomelTesty = pd.DataFrame(y_test_neomel)
df_neomelTest = pd.concat([df_neomelTestx, df_neomelTesty], axis=1)
print(df_neomelTestx)
print(df_neomelTesty)
print(df_neomelTest)
df_neomelTest.to_csv('neomelTest.csv')
files.download('neomelTest.csv')

df_albalbTestx = pd.DataFrame(x_test_albalb)
df_albalbTesty = pd.DataFrame(y_test_albalb)
df_albalbTest = pd.concat([df_albalbTestx, df_albalbTesty], axis=1)
print(df_albalbTestx)
print(df_albalbTesty)
print(df_albalbTest)
df_albalbTest.to_csv('albalbTest.csv')
files.download('albalbTest.csv')

df_blibjoTestx = pd.DataFrame(x_test_blibjo)
df_blibjoTesty = pd.DataFrame(y_test_blibjo)
df_blibjoTest = pd.concat([df_blibjoTestx, df_blibjoTesty], axis=1)
df_blibjoTest.to_csv('blibjoTest.csv')
files.download('blibjoTest.csv')

df_chonasTestx = pd.DataFrame(x_test_chonas)
df_chonasTesty = pd.DataFrame(y_test_chonas)
df_chonasTest = pd.concat([df_chonasTestx, df_chonasTesty], axis=1)
df_chonasTest.to_csv('chonasTest.csv')
files.download('chonasTest.csv')

df_gymschTestx = pd.DataFrame(x_test_gymsch)
df_gymschTesty = pd.DataFrame(y_test_gymsch)
df_gymschTest = pd.concat([df_gymschTestx, df_gymschTesty], axis=1)
df_gymschTest.to_csv('gymschTest.csv')
files.download('gymschTest.csv')

df_leuaspTestx = pd.DataFrame(x_test_leuasp)
df_leuaspTesty = pd.DataFrame(y_test_leuasp)
df_leuaspTest = pd.concat([df_leuaspTestx, df_leuaspTesty], axis=1)
df_leuaspTest.to_csv('leuaspTest.csv')
files.download('leuaspTest.csv')

df_leuiduTestx = pd.DataFrame(x_test_leuidu)
df_leuiduTesty = pd.DataFrame(y_test_leuidu)
df_leuiduTest = pd.concat([df_leuiduTestx, df_leuiduTesty], axis=1)
df_leuiduTest.to_csv('leuiduTest.csv')
files.download('leuiduTest.csv')

df_lotlotTestx = pd.DataFrame(x_test_lotlot)
df_lotlotTesty = pd.DataFrame(y_test_lotlot)
df_lotlotTest = pd.concat([df_lotlotTestx, df_lotlotTesty], axis=1)
df_lotlotTest.to_csv('lotlotTest.csv')
files.download('lotlotTest.csv')

df_neofluTestx = pd.DataFrame(x_test_neoflu)
df_neofluTesty = pd.DataFrame(y_test_neoflu)
df_neofluTest = pd.concat([df_neofluTestx, df_neofluTesty], axis=1)
df_neofluTest.to_csv('neofluTest.csv')
files.download('neofluTest.csv')

df_perfluTestx = pd.DataFrame(x_test_perflu)
df_perfluTesty = pd.DataFrame(y_test_perflu)
df_perfluTest = pd.concat([df_perfluTestx, df_perfluTesty], axis=1)
df_perfluTest.to_csv('perfluTest.csv')
files.download('perfluTest.csv')

df_ponkesTestx = pd.DataFrame(x_test_ponkes)
df_ponkesTesty = pd.DataFrame(y_test_ponkes)
df_ponkesTest = pd.concat([df_ponkesTestx, df_ponkesTesty], axis=1)
df_ponkesTest.to_csv('ponkesTest.csv')
files.download('ponkesTest.csv')

df_romvlaTestx = pd.DataFrame(x_test_romvla)
df_romvlaTesty = pd.DataFrame(y_test_romvla)
df_romvlaTest = pd.concat([df_romvlaTestx, df_romvlaTesty], axis=1)
df_romvlaTest.to_csv('romvlaTest.csv')
files.download('romvlaTest.csv')

df_rutrutTestx = pd.DataFrame(x_test_rutrut)
df_rutrutTesty = pd.DataFrame(y_test_rutrut)
df_rutrutTest = pd.concat([df_rutrutTestx, df_rutrutTesty], axis=1)
df_rutrutTest.to_csv('rutrutTest.csv')
files.download('rutrutTest.csv')

df_rutvirTestx = pd.DataFrame(x_test_rutvir)
df_rutvirTesty = pd.DataFrame(y_test_rutvir)
df_rutvirTest = pd.concat([df_rutvirTestx, df_rutvirTesty], axis=1)
df_rutvirTest.to_csv('rutvirTest.csv')
files.download('rutvirTest.csv')

df_sanlucTestx = pd.DataFrame(x_test_sanluc)
df_sanlucTesty = pd.DataFrame(y_test_sanluc)
df_sanlucTest = pd.concat([df_sanlucTestx, df_sanlucTesty], axis=1)
df_sanlucTest.to_csv('sanlucTest.csv')
files.download('sanlucTest.csv')

df_sanvolTestx = pd.DataFrame(x_test_sanvol)
df_sanvolTesty = pd.DataFrame(y_test_sanvol)
df_sanvolTest = pd.concat([df_sanvolTestx, df_sanvolTesty], axis=1)
df_sanvolTest.to_csv('sanvolTest.csv')
files.download('sanvolTest.csv')

df_squcepTestx = pd.DataFrame(x_test_squcep)
df_squcepTesty = pd.DataFrame(y_test_squcep)
df_squcepTest = pd.concat([df_squcepTestx, df_squcepTesty], axis=1)
df_squcepTest.to_csv('squcepTest.csv')
files.download('squcepTest.csv')

df_vimvimTestx = pd.DataFrame(x_test_vimvim)
df_vimvimTesty = pd.DataFrame(y_test_vimvim)
df_vimvimTest = pd.concat([df_vimvimTestx, df_vimvimTesty], axis=1)
df_vimvimTest.to_csv('vimvimTest.csv')
files.download('vimvimTest.csv')

df_zinstrTestx = pd.DataFrame(x_test_zinstr)
df_zinstrTesty = pd.DataFrame(y_test_zinstr)
df_zinstrTest = pd.concat([df_zinstrTestx, df_zinstrTesty], axis=1)
df_zinstrTest.to_csv('zinstrTest.csv')
files.download('zinstrTest.csv')

df_zinzinTestx = pd.DataFrame(x_test_zinzin)
df_zinzinTesty = pd.DataFrame(y_test_zinzin)
df_zinzinTest = pd.concat([df_zinzinTestx, df_zinzinTesty], axis=1)
df_zinzinTest.to_csv('zinzinTest.csv')
files.download('zinzinTest.csv')

df_egyedszamTestx = pd.DataFrame(x_test_egyedszam)
df_egyedszamTesty = pd.DataFrame(y_test_egyedszam)
df_egyedszamTest = pd.concat([df_egyedszamTestx, df_egyedszamTesty], axis=1)
df_egyedszamTest.to_csv('egyedszamTest.csv')
files.download('egyedszamTest.csv')

df_fajszamTestx = pd.DataFrame(x_test_fajszam)
df_fajszamTesty = pd.DataFrame(y_test_fajszam)
df_fajszamTest = pd.concat([df_fajszamTestx, df_fajszamTesty], axis=1)
df_fajszamTest.to_csv('fajszamTest.csv')
files.download('fajszamTest.csv')

df_neomelTest

df_sum_tobbseg_A = pd.concat([df_albalbTest,	df_blibjoTest,	df_chonasTest,	df_gymschTest,	df_leuaspTest,	df_leuiduTest,df_lotlotTest,	df_neofluTest,	df_perfluTest,	df_ponkesTest,	df_romvlaTest,	df_rutrutTest,	df_rutvirTest,	df_sanlucTest,	df_sanvolTest,	df_squcepTest,	df_vimvimTest,	df_zinstrTest,	df_zinzinTest, df_fajszamTest], axis = 1)

a = pd.merge(pd.merge(df_albalbTest,	df_blibjoTest),	df_chonasTest)

b = pd.merge(pd.merge(a,df_gymschTest),df_leuaspTest)

c = pd.merge(pd.merge(b,df_leuiduTest),df_lotlotTest)

d = pd.merge(pd.merge(c,	df_neofluTest),df_perfluTest)

e = pd.merge(pd.merge(d,	df_ponkesTest),df_romvlaTest)
f = pd.merge(pd.merge(e, df_rutrutTest),	df_rutvirTest)
g = pd.merge(pd.merge(f, df_sanlucTest),	df_sanvolTest)
h = pd.merge(pd.merge(g, df_squcepTest),	df_vimvimTest)
i = pd.merge(pd.merge(h, df_zinstrTest),	df_zinzinTest)
j = pd.merge(i,	df_fajszamTest)

df_sum_tobbseg = j

df_sum_tobbseg.to_csv('validacios_tobbseg.csv')
files.download('validacios_tobbseg.csv')

df_sum_NeomelEsEgyedszam = pd.merge(df_neomelTest, df_egyedszamTest)

df_sum_NeomelEsEgyedszam

df_neomelTest

df_egyedszamTest

df_sum_NeomelEsEgyedszam.to_csv('validacios_kisebbseg.csv')
files.download('validacios_kisebbseg.csv')